---
title: 'Elite Dangerous: Guardians I'
author: CMDR immerlicht
date: '3310-02-01'
categories:
  - elite-dangerous
  - code
  - analysis

image: HighResScreenShot_2023-01-06_19-cropped.jpg
echo: false
output: true
draft: false
format:
  html:
    toc: true
    reference-location: margin
  typst:
    toc: true
    keep-typ: true
     
title-block-banner: true

---


```{python}
#
import os, datetime
import json
import numpy as np
import pandas as pd
from collections import namedtuple
from io import StringIO
from itertools import accumulate, permutations, combinations, product
from sklearn.cluster import DBSCAN
from scipy.interpolate import interp1d, LinearNDInterpolator


from IPython.display import display
from IPython.display import Markdown

from edcompanion.linalg.fitsvd import fitline
from edcompanion.md.edastro import create_galaxymap_url, embed_galaxymap

```

```{python}

NT_Line = namedtuple('line_nd',['support', 'direction'])

def project_point_on_line(point, support, direction, rounding=1):

    """Projects a point on a line"""

    dp = np.dot(np.asarray(point)-np.asarray(support), np.asarray(direction) )
    return np.round(dp*np.asarray(direction) + np.asarray(support), rounding)

def distance_point_to_line(point, support, direction):

    """Calculate distance between point and a line"""

    return np.linalg.norm(
        np.cross(
            direction,
            point - support,
            axis=-1),
        axis=-1) / np.linalg.norm(direction,axis=-1)

def line_from_points(points):

    """Fit a line through a set of points
        from: https://ltetrel.github.io/data-science/2018/06/08/line_svd.html

        returns named tuple with properties support and direction."""

    return NT_Line(*fitline(points))


```



## Introduction


The Guardians, a lost, enigmatic civilization that left us beacons and ruins, millions of years old, yet all still functional. They were technologically advanced and colonized part of the Orion arm long before humans learned to travel between stars, long before we even existed.

Not one decade after their initial discovery a remarkable 300 systems have been discovered with remains of this mysterious civilization.


More information and research on the Guardians you can find with [Canonn Research / The Guardians](https://canonn.science/codex/the-guardians/).


### An observation

The [Interactive Galactic Map](https://edastro.com/galmap/) with EDAstro can display markersfor known systems with guardian sites, the result can be seen in @fig-astro-guardian-sites. 

![Galactic Map with Guardian sites](Web capture_4-2-2024_203931_edastro.com.jpeg){#fig-astro-guardian-sites}

Looking at this map we immediately recognize these markers appear to lie on two lines that intersect somewhere at the border between the Formidine Rift and the Errant Marches.


## First analysis

Canonn Research maintains data on discoveries related to the Guardians. We use the coordinate data Canonn Research and collect them into a minimal dataframe for further use.

```{python}

guardiandata_path = os.path.join(os.getcwd(), 'data')

guardiandata_files = {n.split(' - ')[2].split('.')[-2]:os.path.join(guardiandata_path, n) for n in os.listdir(guardiandata_path) if 'Canonn - Guardians' in n}
guardiandata = {n:pd.read_csv(p) for n,p in guardiandata_files.items()}

```


```{python}
soi = ['Ruins','Structures']+ ['Beacons']

inter_columns = list([i for i in accumulate([set(guardiandata['Guardian '+n].columns) for n in soi], lambda D1, D2: D1 & D2)][-1])
union_columns = list([i for i in accumulate([set(guardiandata['Guardian '+n].columns) for n in soi], lambda D1, D2: D1 | D2)][-1])

column_order_inter = {c:i for c,i in zip(guardiandata['Guardian Beacons'].columns, range(len(guardiandata['Guardian Beacons'].columns))) }
inter_columns = sorted(inter_columns, key=lambda I:column_order_inter.get(I,100))
union_columns = sorted(union_columns, key=lambda I:column_order_inter.get(I,100))
numeric_columns = set([ 'x', 'y', 'z','Distance To Arrival', 'Orbital Eccentricity', 'Surface Temperature', 'Rotational Period',])

column_dtypes = dict(
    Type=np.dtype(str),
    **{
        c:np.dtype(float if c in numeric_columns else str)
        for c in union_columns
    }
)

# In text 
guardiandata_filedate = datetime.date.fromtimestamp(os.path.getmtime(guardiandata_files['Guardian Ruins'])).isoformat()
soi_names = ', '.join(['Guardian '+n for n in soi][0:-1]) + ' and Guardian '+soi[-1]


```

There are `{python} len(soi)` sheets we are using, `{python} soi_names`.
These sheets were downloaded from the Canonn Research website as csv files on `{python} guardiandata_filedate`. 


```{python}
ignore_columns = set(['SiteId','Reported By'])
system_columns = [c for c in inter_columns if c not in ignore_columns]
```


```{python}
soi_systems = [
    {
        "Type":g,
        **{
            c:r[c] 
            for c in system_columns

        }
    }
    for g in soi 
    for i, r in guardiandata['Guardian '+g].iterrows()
]
df_systems = pd.DataFrame(soi_systems, columns=['Type']+system_columns)#.set_index(['Type','System Name'])
df_coordinates = df_systems[['System Name', 'x', 'y', 'z']].drop_duplicates()
soi_coordinates = df_coordinates[['x', 'y', 'z']].to_numpy()

```

They hold information on a total of `{python} len(df_systems)` records for sites in `{python} len(soi_coordinates)` systems.

### Clusters and outliers


On the Galactic Map with Guardian Sites (@fig-astro-guardian-sites) we recognize sites are clustered - mostly along travel routes - and if we cluster using DBSCAN^[Density-based spatial clustering; given a set of points in some space, it groups together points that are closely packed (points with many nearby neighbors), and marks as outliers points that lie alone in low-density regions (those whose nearest neighbors are too far away)] we can identify both the groups of sites and outliers.

```{python}
#| echo: true
dbscan_parameters = dict(
    eps=200,        # maximum distance between neighbours
    min_samples=3   # minimum size of a cluster
)

```
```{python}
#| echo: false
coord_clusters = DBSCAN(**dbscan_parameters).fit(soi_coordinates)

```


With these parameters we identify `{python} str(len(np.unique(coord_clusters.labels_)))` clusters and `{python} str(np.sum(np.less(coord_clusters.labels_, 0)))` outliers

#### Outliers

```{python}
#| output: true
outliers = np.copy(soi_coordinates[np.less(coord_clusters.labels_,0)])
outlier_systemnames = df_coordinates[np.less(coord_clusters.labels_,0)]
outlier_systemnames.set_index(['System Name']).round(1)
```
```{python}
guardian_outliers_json_pins = "guardian-outliers.json"

with open(guardian_outliers_json_pins, 'wt') as of:
    json.dump(dict(markers=[
            dict(
                pin='red',
                text=f"{row[1]['System Name']}",
                **{c:round(row[1][c],1) for c in ['x','y','z'] }
            )
            for row in outlier_systemnames.iterrows()
        ] ), of, indent=3)
```

```{python}

Markdown(f"""

{embed_galaxymap(guardian_outliers_json_pins)}


"""
)

```

#### Clusters

The centers of the `{python} str(len(np.unique(coord_clusters.labels_)))` clusters can be seen in the interactive map below, with the number of sites in each cluster. 

```{python}
guardian_clusters_json_pins = "guardian-clusters.json"
with open(guardian_clusters_json_pins, 'wt') as of:
    json.dump(dict(markers=[
            dict(
                pin='yellow',
                text=f'Center of cluster {row[0]} with {row[2]} guardian sites',
                **{c:v for c,v in zip(['x','y','z'], row[1])}
            )
            for row in [
                (
                    l, np.round(np.mean(soi_coordinates[np.equal(coord_clusters.labels_,l)], axis=0),2).tolist(), np.count_nonzero(np.equal(coord_clusters.labels_,l)) 
                )
                for l in np.unique(coord_clusters.labels_) 
                if not l < 0]
        ]), of, indent=3)
```

```{python}
#| cap-location: top
#| caption: Clusters of Guardian sites
Markdown(f"""

{embed_galaxymap(guardian_clusters_json_pins, layer='heatmap')}


"""
)

```

The centre of each cluster is found by taking the mean of the coordinates of the sites of each cluster.
```{python}	
cluster_centers = np.round([
    np.mean(
        soi_coordinates[np.equal(coord_clusters.labels_,l)], axis=0
    ) 
    for l in np.unique(coord_clusters.labels_) if l >= 0], 2)

```

We now apply DBSCAN to the centre of each cluster to identify the groups we are looking for with the following parameters:

```{python}
#| echo: true
dbscan_parameters = dict(
    eps=10000,        # maximum distance between neighbouring centres
    min_samples=3     # minimum number of centres
)

```
```{python}	

group_clusters = DBSCAN(**dbscan_parameters).fit(cluster_centers)
#print([(l, np.count_nonzero(np.equal(group_clusters.labels_,l))) for l in np.unique(group_clusters.labels_)])
guardian_groups = {l:cluster_centers[np.equal(group_clusters.labels_,l)] for l in np.unique(group_clusters.labels_)}
```

We easily distinguish the `{python} str(len(np.unique(group_clusters.labels_)))` groups.

```{python}
guardian_two_goups_json_pins = "guardian-two-groups.json"

with open(guardian_two_goups_json_pins, 'wt') as of:
    json.dump(dict(markers=[
            dict(
                pin='yellow', text=f'group 0 {str(row)}',
                **{c:v for c,v in zip(['x','y','z'], row)}
            )
            for row in guardian_groups[0]
        ] + [
            dict(
                pin='green', text=f'group 1 {str(row)}',
                **{c:v for c,v in zip(['x','y','z'], row)}
            )
            for row in guardian_groups[1]
        ]), of, indent=3)	
```


::: {#fig-astro-two-groups}

```{python}
fig_url = create_galaxymap_url(
    markers = guardian_two_goups_json_pins,
    layer = 'heatmap')

Markdown(f"""
{embed_galaxymap(guardian_two_goups_json_pins, layer='heatmap')}


"""
)

```

The groups are found by applying DBSCAN to the centres of the clusters. [edastro link](`{python} fig_url`). 

:::

### Fitting the lines pt.I - clusters

We first use the `{python} str(len(np.unique(group_clusters.labels_)))` cluster groups we found and for each group fit a lines through their centers.

```{python}	

guardian_clusters = {l:cluster_centers[np.equal(group_clusters.labels_,l)] for l in np.unique(group_clusters.labels_)}
guardian_cluster_lines = {
    int(l):line_from_points(cluster_centers[np.equal(group_clusters.labels_,l)])
    for l in np.unique(group_clusters.labels_)
}

guardian_cluster_distances = {
    int(l):np.round(distance_point_to_line(guardian_clusters[l], *guardian_cluster_lines[l]),2)
    for l in np.unique(group_clusters.labels_)
}

```


```{python}	

for group in guardian_cluster_distances:

    print(f"\nGroup {group} Mean distance {np.mean(guardian_cluster_distances[group])} ")
    i = 0
    glmask = np.ones(len(guardian_cluster_distances[group]), dtype=bool)

    glp = np.percentile(guardian_cluster_distances[group][glmask], 80)
    glmask = np.less(guardian_cluster_distances[group], glp)
    print(glp, glmask)

    guardian_cluster_lines[group] = line_from_points(guardian_clusters[group][glmask])
    guardian_cluster_distances[group] = np.round(distance_point_to_line(guardian_clusters[group], *guardian_cluster_lines[group]),2)
    print(f"\nGroup {group} Mean distance {np.mean(guardian_cluster_distances[group][glmask])} ")


```


```{python}
guardian_projected_clusters_json_pins_1 = "guardian-projected-clusters-1.json"
with open(guardian_projected_clusters_json_pins_1, 'wt') as of:
        json.dump(dict(markers=[
        dict(
            pin='white',
            text=f"group {l}, distance {round(distance_point_to_line(cc, *guardian_cluster_lines[l]),1)}\ncentre \t{cc}\nprojected \t{project_point_on_line(cc, *guardian_cluster_lines[l])}",
            **{c:v for c,v in zip(['x','y','z'], list(project_point_on_line(cc, *guardian_cluster_lines[l])))}
        )
        for l in np.unique(group_clusters.labels_) 
        for cc in guardian_clusters[l]
        if not l < 0
    ]),of,indent=3)
```


::: {#fig-astro-projected_clusters-1}

```{python}
fig_url = create_galaxymap_url(
    markers = [guardian_projected_clusters_json_pins_1, guardian_clusters_json_pins],
    layer = 'heatmap')

Markdown(f"""
{embed_galaxymap( [guardian_projected_clusters_json_pins_1, guardian_clusters_json_pins], layer='heatmap')}


"""
)

```

The clusters and their  projection on the calculated lines. [edastro link](`{python} fig_url`). 

:::

### Fitting the lines pt.II - systems

We now group the system coordinates to the `{python} str(len(np.unique(group_clusters.labels_)))` cluster groups we found and for each group fit a lines through the _systems_ like we saw in @fig-astro-guardian-sites.

```{python}	
guardian_systems_grouping = group_clusters.labels_[coord_clusters.labels_]

guardian_groups = {l:soi_coordinates[np.equal(guardian_systems_grouping,l)] for l in np.unique(guardian_systems_grouping)}
```


```{python}	

glines = {
    int(l):line_from_points(soi_coordinates[np.equal(guardian_systems_grouping,l)])
    for l in np.unique(group_clusters.labels_)
}

gsystem_lines = {
    int(l):line_from_points(soi_coordinates[np.equal(guardian_systems_grouping,l)])._asdict()
    for l in np.unique(group_clusters.labels_)
}

```


Calculating the distance of systems to each line we find for mean and variance of these distances


```{python}	
guardian_groups_distances = {
    int(l):np.round(distance_point_to_line(guardian_groups[l], *glines[l]),2)
    for l in np.unique(group_clusters.labels_)
}

guardian_groups_distances_mean = {
    int(l):np.round(np.mean(guardian_groups_distances[l]),2)
    for l in np.unique(group_clusters.labels_)
}

guardian_groups_distances_std = {
    int(l):np.round(np.std(guardian_groups_distances[l]),2)
    for l in np.unique(group_clusters.labels_)
}

guardian_groups_distances_max = {
    int(l):np.round(np.amax(guardian_groups_distances[l]),2)
    for l in np.unique(group_clusters.labels_)
}

```




```{python}
pd.DataFrame(
    dict(
        group=np.unique(group_clusters.labels_),
        mean=guardian_groups_distances_mean.values(),
        std = guardian_groups_distances_std.values(),
        max = guardian_groups_distances_max.values(),
        count=[len(guardian_groups[l]) for l in np.unique(group_clusters.labels_)] 
    ),
).set_index('group')
```


We find some systems quite far from 'their' line, so we'll filter at the 90th percentile of the distances, then recalculate lines with those systems only and repeat a few iterations


```{python}	

for group in guardian_groups_distances:
    print(f"\nGroup {group} Mean distance {guardian_groups_distances_mean[group]} Std {guardian_groups_distances_std[group]} Max {guardian_groups_distances_max[group]}")
    i = 0
    glmask = np.ones(len(guardian_groups_distances[group]), dtype=bool)
    while i < 9:
        glp = np.percentile(guardian_groups_distances[group][glmask], 90)
        glmask = np.less(guardian_groups_distances[group], glp)

        glines[group] = line_from_points(guardian_groups[group][glmask])
        guardian_groups_distances[group] = np.round(distance_point_to_line(guardian_groups[group], *glines[group]),2)

        guardian_groups_distances_mean[group] = np.round(np.mean(guardian_groups_distances[group][glmask]),2)
        guardian_groups_distances_std[group] = np.round(np.std(guardian_groups_distances[group][glmask]),2)
        guardian_groups_distances_max[group] = np.round(np.amax(guardian_groups_distances[group][glmask]),2)

        system_count = len(guardian_groups[group][glmask])
        print(f"Group {group}, {system_count} systems, Mean distance {guardian_groups_distances_mean[group]} Std {guardian_groups_distances_std[group]} Max {guardian_groups_distances_max[group]}")
        i += 1

        if system_count / len(guardian_groups[group]) < 0.67:
            break
```



```{python}
pd.DataFrame(
    dict(
        group=np.unique(group_clusters.labels_),
        mean=guardian_groups_distances_mean.values(),
        std = guardian_groups_distances_std.values(),
        max = guardian_groups_distances_max.values()
    ),
).set_index('group')
```



```{python}
guardian_lines_json_pins = "guardian-lines.json"
with open(guardian_lines_json_pins, 'wt') as of:
        json.dump(dict(markers=[
        dict(
            pin='white',
            text=f"group {l}",
            **{c:v for c,v in zip(['x','y','z'], list(glines[l].support + 2000*s*glines[l].direction))}
        )
        for l in np.unique(group_clusters.labels_) 
        for s in range(-5,6)
        if not l < 0
    ]),of,indent=3)
```


```{python}	

```


```{python}	
pd.DataFrame(
    dict(
        cluster=[cc for cc in np.unique(coord_clusters.labels_) if cc >=0],
        group=group_clusters.labels_,
        distance=np.round(distance_point_to_line(cluster_centers, *glines[group]),2),
    
)).set_index(['group','cluster'])
```


```{python}
guardian_projected_clusters_json_pins_2 = "guardian-projected-clusters-2.json"
with open(guardian_projected_clusters_json_pins_2, 'wt') as of:
        json.dump(dict(markers=[
        dict(
            pin='white',
            text=f"group {l}, distance {round(distance_point_to_line(cc, *glines[l]),1)}\ncentre \t{cc}\nprojected \t{project_point_on_line(cc, *glines[l])}",
            **{c:v for c,v in zip(['x','y','z'], list(project_point_on_line(cc, *glines[l])))}
        )
        for l in np.unique(group_clusters.labels_) 
        for cc in cluster_centers[np.equal(group_clusters.labels_,l)]
        if not l < 0
    ]),of,indent=3)
```


::: {#fig-astro-projected_clusters}

```{python}
fig_url = create_galaxymap_url(
    markers = [guardian_projected_clusters_json_pins_2, guardian_clusters_json_pins],
    layer = 'heatmap')

Markdown(f"""
{embed_galaxymap( [guardian_projected_clusters_json_pins_2, guardian_clusters_json_pins], layer='heatmap')}


"""
)

```

The clusters and their  projection on the calculated lines. [edastro link](`{python} fig_url`). 

:::


### References


